import { tf, } from './dependencies.generated';
import { isShape4D, isValidRange, MODEL_DEFINITION_VALIDATION_CHECK_ERROR_TYPE, } from '@upscalerjs/core';
import { isLayersModel, } from './isLayersModel';
export class AbortError extends Error {
    message = 'The upscale request received an abort signal';
}
const ERROR_MISSING_MODEL_DEFINITION_PATH_URL = 'https://upscalerjs.com/documentation/troubleshooting#missing-model-path';
const ERROR_INVALID_MODEL_TYPE_URL = 'https://upscalerjs.com/documentation/troubleshooting#invalid-model-type';
const WARNING_INPUT_SIZE_AND_PATCH_SIZE_URL = 'https://upscalerjs.com/documentation/troubleshooting#input-size-and-patch-size';
const ERROR_WITH_MODEL_INPUT_SHAPE_URL = 'https://upscalerjs.com/documentation/troubleshooting#error-with-model-input-shape';
export const ERROR_MISSING_MODEL_DEFINITION_PATH = [
    'You must provide a "path" when providing a model definition',
    `For more information, see ${ERROR_MISSING_MODEL_DEFINITION_PATH_URL}.`,
].join('\n');
export const ERROR_INVALID_MODEL_TYPE = (modelType) => ([
    `You've provided an invalid model type: ${JSON.stringify(modelType)}. Accepted types are "layers" and "graph".`,
    `For more information, see ${ERROR_INVALID_MODEL_TYPE_URL}.`,
].join('\n'));
export const ERROR_MODEL_DEFINITION_BUG = 'There is a bug with the upscaler code. Please report this.';
export const WARNING_INPUT_SIZE_AND_PATCH_SIZE = [
    'You have provided a patchSize, but the model definition already includes an input size.',
    'Your patchSize will be ignored.',
    `For more information, see ${WARNING_INPUT_SIZE_AND_PATCH_SIZE_URL}.`,
].join('\n');
export const ERROR_WITH_MODEL_INPUT_SHAPE = (inputShape) => [
    `Expected model to have a rank-4 compatible input shape. Instead got: ${JSON.stringify(inputShape)}.`,
    `For more information, see ${ERROR_WITH_MODEL_INPUT_SHAPE_URL}.`,
].join('\n');
export function getModelDefinitionError(error, modelDefinition) {
    switch (error) {
        case MODEL_DEFINITION_VALIDATION_CHECK_ERROR_TYPE.MISSING_PATH:
            return new Error(ERROR_MISSING_MODEL_DEFINITION_PATH);
        case MODEL_DEFINITION_VALIDATION_CHECK_ERROR_TYPE.INVALID_MODEL_TYPE:
            return new Error(ERROR_INVALID_MODEL_TYPE(modelDefinition?.modelType));
        default:
            return new Error(ERROR_MODEL_DEFINITION_BUG);
    }
}
export const warn = (msg) => {
    console.warn(Array.isArray(msg) ? msg.join('\n') : msg);
};
export function isProgress(p) { return p !== undefined && typeof p === 'function'; }
export function isSingleArgProgress(p) { return isProgress(p) && p.length <= 1; }
export const isMultiArgTensorProgress = (p, output, progressOutput) => {
    if (!isProgress(p) || p.length <= 1) {
        return false;
    }
    return progressOutput === undefined && output === 'tensor' || progressOutput === 'tensor';
};
export const isAborted = (abortSignal) => {
    if (abortSignal) {
        return abortSignal.aborted;
    }
    return false;
};
export async function wrapGenerator(gen, postNext) {
    let result;
    for (result = await gen.next(); !result.done; result = await gen.next()) {
        if (postNext) {
            await postNext(result.value);
        }
    }
    return result.value;
}
export function isModelDefinitionFn(modelDefinition) { return typeof modelDefinition === 'function'; }
export const tensorAsClampedArray = (tensor) => tf.tidy(() => {
    const [height, width,] = tensor.shape;
    const fill = tf.fill([height, width,], 255).expandDims(2);
    return tensor.clipByValue(0, 255).concat([fill,], 2).dataSync();
});
export function getModel(modelDefinition) {
    return isModelDefinitionFn(modelDefinition) ? modelDefinition(tf) : modelDefinition;
}
function nonNullable(value) {
    return value !== null && value !== undefined;
}
export function processAndDisposeOfTensor(tensor, ..._processFns) {
    const processFns = _processFns.filter(nonNullable);
    if (processFns.length) {
        const processedTensor = tf.tidy(() => processFns.reduce((reducedTensor, processFn) => processFn(reducedTensor), tensor));
        if (!tensor.isDisposed && tensor !== processedTensor) {
            tensor.dispose();
        }
        return processedTensor;
    }
    return tensor;
}
export async function loadTfModel(modelPath, modelType = 'layers') {
    if (modelType === 'graph') {
        return await tf.loadGraphModel(modelPath);
    }
    return await tf.loadLayersModel(modelPath);
}
const getBatchInputShape = (model) => {
    if (isLayersModel(model)) {
        return model.layers[0].batchInputShape;
    }
    return model.inputs[0].shape;
};
export const getInputShape = (model) => {
    const batchInputShape = getBatchInputShape(model);
    if (isShape4D(batchInputShape)) {
        return batchInputShape;
    }
    throw new Error(ERROR_WITH_MODEL_INPUT_SHAPE(batchInputShape));
};
export const scaleIncomingPixels = (range) => (tensor) => {
    if (isValidRange(range) && range[1] === 1) {
        return tf.mul(tensor, 1 / 255);
    }
    return tensor;
};
const isInputSizeDefined = (inputShape) => Boolean(inputShape) && isShape4D(inputShape) && Boolean(inputShape[1]) && Boolean(inputShape[2]);
export const parsePatchAndInputSizes = (model, { patchSize, padding, }) => {
    const inputShape = getInputShape(model);
    if (isInputSizeDefined(inputShape) && patchSize !== undefined) {
        warn(WARNING_INPUT_SIZE_AND_PATCH_SIZE);
    }
    if (isInputSizeDefined(inputShape)) {
        if (inputShape[1] !== inputShape[2]) {
            throw new Error('Input shape must be square');
        }
        return {
            patchSize: inputShape[1] - (padding || 0) * 2,
            padding,
        };
    }
    return {
        patchSize,
        padding,
    };
};
export const padInput = (inputShape) => (pixels) => {
    const pixelsHeight = pixels.shape[1];
    const pixelsWidth = pixels.shape[2];
    if (isInputSizeDefined(inputShape) && (inputShape[1] > pixelsHeight || inputShape[2] > pixelsWidth)) {
        return tf.tidy(() => {
            const height = Math.max(pixelsHeight, inputShape[1]);
            const width = Math.max(pixelsWidth, inputShape[2]);
            const rightTensor = tf.zeros([1, pixelsHeight, width - pixelsWidth, 3,]);
            const bottomTensor = tf.zeros([1, height - pixelsHeight, width, 3,]);
            const topTensor = tf.concat([pixels, rightTensor,], 2);
            const final = tf.concat([topTensor, bottomTensor,], 1);
            return final;
        });
    }
    return pixels;
};
export const trimInput = (imageSize, scale) => (pixels) => {
    const height = imageSize[1] * scale;
    const width = imageSize[2] * scale;
    if (height < pixels.shape[1] || width < pixels.shape[2]) {
        return tf.tidy(() => tf.slice(pixels, [0, 0, 0,], [1, height, width, 3,]));
    }
    return pixels;
};
export const scaleOutput = (range) => (pixels) => {
    const endingRange = isValidRange(range) ? range[1] : 255;
    return pixels.clipByValue(0, endingRange).mul(endingRange === 1 ? 255 : 1);
};
